{
  "metadata": {
    "subtask_count": 5,
    "categories": [
      "Web Frontend Development (UI/Rendering)",
      "Game Logic & Rule Adjudication",
      "State Management (Undo/Redo/Replay)",
      "Simple Rule-Based/Heuristic AI",
      "Advanced AI (Search Algorithms, e.g., Minimax)"
    ]
  },
  "query": "Subtask 1: Render Board & Basic Moves \nGoal: Implement a 15×15 board rendering, black and white alternate moves (no win detection yet). \nConstraints: \n- Only native HTML/CSS/JS; no third-party libraries. \n- Board supports click-to-place, disallowing stones on occupied points. \n- Provide a \"Reset\" button. \nDeliverables: \n- Files: index.html, styles.css, app.js. \n- Board as equal-spaced grid (Canvas or DOM). \nAcceptance Criteria: \n- Black moves first. \n- Each valid click places a stone on the nearest intersection. \n- No duplicate moves on the same intersection. \n- After reset, board clears and black starts again. \n\nSubtask 2: Win Detection & Highlight Five \nGoal: On top of Task 1, add detection of five in a row (horizontal, vertical, both diagonals). Highlight winning sequence and lock board. \nConstraints: \n- After victory, forbid further moves; \"Reset\" starts a new game. \n- Detection algorithm should be O(1) incremental neighborhood check or O(n) range (no full scan). \nDeliverables: \n- Highlight 5 winning stones with line or glow. \n- Display \"Black Wins / White Wins\" at page top. \n- Detection code in standalone function: checkWin(lastMove). \nAcceptance Criteria: \n- Immediate win when 5 in a row is formed. \n- Six or more in a row still counts as win (standard Gomoku rule). \n- Edge-of-board wins are detected correctly. \n- Clicking occupied or locked board is invalid. \n\nSubtask 3: Local Multiplayer + Undo/Replay \nGoal: Support local two-player game management: move history, undo/redo, and step-by-step replay. \nConstraints: \n- Maintain moves[] stack, each element includes coordinates and color. \n- Undo allows branching (history truncates). \n- After game ends, replay and restart still available. \nDeliverables: \n- Buttons: Undo, Redo, Replay (more than 300ms per move). \n- Board edges show coordinates (A–O / 1–15). \nAcceptance Criteria: \n- Undo back to opening without error. \n- Redo returns to latest step. \n- During replay, no manual moves allowed. \n- After replay ends, normal play resumes. \n- Undoing past winning move unlocks board. \n\nSubtask 4: Basic AI (Easy/Medium) \nGoal: Add Human vs AI mode with simple AI. \nEasy: Random legal moves, prefer central 7×7. \nMedium: If winning in 1 move → take it. Else block opponent's open four. Else use scoring (open three blocked three open two). \nConstraints: \n- Mode selection: Local PvP / Human vs AI (choose who moves first). \n- AI must decide within 100ms on empty 15×15 board. \nDeliverables: \n- Dropdown for mode and first player. \n- Status bar: \"AI Thinking...\". \n- AI function: aiMove(level); scoring function modularized. \nAcceptance Criteria: \n- Medium AI blocks human's \"open four\". \n- Medium AI takes immediate winning move. \n- Easy AI significantly weaker (Medium more than 70% win rate over Easy). \n\nSubtask 5: Advanced AI (Hard/Expert) \nGoal: Implement stronger AI difficulty with performance control. \nHard: Minimax + Alpha-Beta, fixed depth (2–3 ply), candidate pruning (recent moves, top K scoring). \nExpert: Based on Hard, add iterative deepening, time slicing (e.g. 500ms cutoff), transposition table (hash caching), killer move heuristic. \nConstraints: \n- Provide unified time/node count metrics in UI (e.g. \"depth d=3, nodes n=12,345, time=0.43s\"). \n- Search must obey time limit; return best evaluation so far. \nDeliverables: \n- Difficulty: Easy / Medium / Hard / Expert; selectable first player. \n- Debug panel (collapsible): eval score, candidate list (top K), search stats. \n- Clear function layers: evaluate(board, player), generateCandidates(board), search(root, timeLimit). \nAcceptance Criteria: \n- Hard/Expert prioritize defense against \"open four\" and \"double threats\". \n- Expert expands more nodes than Hard within 500ms and achieves higher win rate. \n- On typical attack/defense test cases, Expert matches or approximates reference solutions."
}