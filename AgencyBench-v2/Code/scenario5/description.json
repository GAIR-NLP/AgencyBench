{
  "subtask_count": 5,
  "subtask1": "Query:\nDesign and implement a minimal but production-ready skeleton for the prompt-based deep research agent, focusing on configuration, dependency injection, and model/tool contracts, without yet implementing multi-step research logic.\nDeliverables:\n- Implement `/workspace/repositories/deep_research_agent/agents/research_agent.py` with a class `ResearchAgent` that:\n  - Accepts in `__init__` explicit dependencies for: (i) a GPT-4.1 client for deep research, (ii) a GPT-4.1-mini client for browsing/planning, (iii) an instance of `SearchEngineTool`, and (iv) an instance of `BrowsingAgent`.\n  - Exposes a public method `run(question: str, metadata: dict | None = None) -> dict` that returns a dict with at least keys `\"answer\"`, `\"trace\"`, and `\"language\"`. In this subtask, `\"answer\"` may be a fixed placeholder string, but `\"trace\"` MUST contain a structured record of the configuration (model names, time budget, tool availability).\n  - Stores an internal field `max_research_time_s` defaulting to 600 seconds and a boolean `must_use_search` defaulting to `True`.\n- Implement `/workspace/repositories/deep_research_agent/agents/research_agent_prompts.py` with clearly named constants for system prompts (e.g., `SYSTEM_PROMPT_RESEARCH_CORE`, `SYSTEM_PROMPT_BROWSING_DELEGATE`) that explicitly state:\n  - GPT-4.1 is the only allowed backbone for deep research and synthesis.\n  - GPT-4.1-mini is the only allowed backbone for browsing-related reasoning.\n  - The agent must not answer fact-seeking questions without consulting the search tool.\n- Add a lightweight sanity test script `/workspace/repositories/deep_research_agent/tests/test_research_agent_skeleton.py` that imports `ResearchAgent`, constructs it with simple mock clients/tools, and calls `run()` on an English and a Chinese question.\nRubric:\n- Import and construction: importing `ResearchAgent` from `agents.research_agent` MUST succeed; constructing it with mock objects for the LLM clients, search tool, and browsing agent MUST not raise exceptions.\n- Configuration trace: calling `ResearchAgent.run(\"Test question\", {})` MUST return a dict in which:\n  - `result[\"answer\"]` is a non-empty string.\n  - `result[\"trace\"]` is a dict containing keys `\"models\"`, `\"tools\"`, and `\"max_research_time_s\"` with correct values reflecting the injected dependencies.\n  - `result[\"language\"]` is either `\"en\"` or `\"zh\"` depending on simple heuristic detection (e.g., presence of CJK characters).\n- Model restriction (static check): a repository-wide search (e.g., using a CI script) for model names in `agents/research_agent.py` and `agents/research_agent_prompts.py` MUST show only allowed backbone strings (e.g., `\"gpt-4.1\"`, `\"gpt-4.1-mini\"`) and MUST NOT contain hard-coded references to any other model identifiers.\n- Dependency purity: `__init__` MUST NOT perform outbound HTTP calls or file I/O; a static or runtime check can confirm that object construction does not access network or the filesystem.\n- Time-budget contract: the `max_research_time_s` attribute MUST be settable via a constructor argument, and `run()` MUST expose this value in `trace[\"max_research_time_s\"]` exactly as stored on the instance.",
  "subtask2": "Query:\nExtend the research agent with a dedicated planning component that decomposes complex questions into sub-questions, determines the working language (English or Chinese), and produces a structured research plan that mandates web search usage.\nDeliverables:\n- In `research_agent.py`, implement a private or internal method (e.g., `_plan_research(self, question: str, metadata: dict | None) -> dict`) that:\n  - Invokes the GPT-4.1 backbone with `SYSTEM_PROMPT_RESEARCH_CORE` to generate a JSON-only plan.\n  - Returns a Python dict with fields at minimum: `\"target_language\"` in {\"en\", \"zh\"}, `\"subquestions\"` (a non-empty list of strings), `\"expected_answer_type\"` (e.g., `\"short_fact\"`, `\"long_explanation\"`), and `\"must_search\"` (boolean, default `True`).\n  - Ensures that at least one `subquestion` explicitly mentions `search` or `web` when `must_search` is `True`.\n- In `research_agent_prompts.py`, produce a precise planner prompt (e.g., `SYSTEM_PROMPT_RESEARCH_CORE`) that:\n  - Instructs the model to always output strict JSON with no extra text.\n  - Requires at least one sub-question that can be directly fed into the `SearchEngineTool` for both English and Chinese inputs.\n  - Explains how to handle bilingual prompts (e.g., Chinese question requiring English sources and vice versa).\n- Update `run()` so that it calls `_plan_research()` and returns the planning output under `trace[\"plan\"]` while still leaving evidence gathering and synthesis as placeholders.\n- Add tests in `tests/test_research_agent_planner.py` that:\n  - Use a mock GPT-4.1 client returning a predetermined JSON plan.\n  - Verify the planner behavior on: (i) a complex English question, (ii) a complex Chinese question, and (iii) a code-mixed bilingual question.\nRubric:\n- JSON-only planning: when `_plan_research()` is called with mocked GPT-4.1 outputs, the method MUST:\n  - Correctly parse the JSON and propagate it as a dict without additional string parsing logic leaking into `run()`.\n  - Raise a controlled exception (or return a structured error plan) if the model response is not valid JSON; the test may inject malformed JSON and verify that the agent fails gracefully.\n- Language routing: for an English question such as `\"What are the main applications of CRISPR in agriculture?\"`, `plan[\"target_language\"]` MUST be `\"en\"`. For a Chinese question like `\"解释量子纠缠在量子通信中的作用\"`, `plan[\"target_language\"]` MUST be `\"zh\"`. For a mixed prompt, the planner MUST choose a single primary `target_language` but document any cross-lingual needs in `plan[\"notes\"]` (if present).\n- Subquestion quality (automated heuristic): each `subquestion` string MUST contain at least 8 characters and at least one alphabetic or CJK character; a simple regex-based checker can enforce this. At least one subquestion MUST mention search intent (e.g., contains tokens `\"search\"`, `\"查找\"`, or `\"web\"`).\n- Must-search enforcement: whenever `plan[\"expected_answer_type\"]` is a fact-seeking type (e.g., `\"short_fact\"` or `\"list_of_facts\"`), `plan[\"must_search\"]` MUST be `True` and this value MUST be recorded in `trace[\"plan\"][\"must_search\"]`.\n- Integration in `run()`: invoking `run()` in tests MUST show that `trace[\"plan\"]` is populated for both English and Chinese sample inputs, and that the placeholder answer is unchanged from Subtask 1, ensuring backward compatibility.",
  "subtask3": "Query:\nImplement the evidence acquisition loop that uses the `SearchEngineTool` and `BrowsingAgent` to perform systematic web search and page-level extraction according to the research plan, supporting both English and Chinese queries and enforcing the time budget.\nDeliverables:\n- In `research_agent.py`, implement a method (e.g., `_gather_evidence(self, plan: dict) -> dict`) that:\n  - Iterates over `plan[\"subquestions\"]`, and for each, calls `SearchEngineTool.search()` at least once.\n  - For each search result, selects the top-K URLs (K configurable, e.g., 3–5), and calls `BrowsingAgent.browse(url, query, language)` (or the appropriate method defined in `browsing_agent.py`) using GPT-4.1-mini.\n  - Accumulates an `evidence` structure containing, for each URL, fields `\"url\"`, `\"title\"`, `\"language\"`, `\"snippets\"`, and `\"supporting_subquestions\"`.\n  - Enforces `max_research_time_s` by tracking wall-clock time and aborting further search if the time limit is exceeded, returning partial evidence and marking `evidence[\"truncated\"] = True`.\n- Integrate `_gather_evidence()` into `run()` such that:\n  - `run()` invokes the planner, then evidence gathering, and returns the evidence structure under `trace[\"evidence\"]`.\n  - `must_use_search` is honored: if `plan[\"must_search\"]` is `True` but no call to `SearchEngineTool.search()` succeeds, `run()` MUST return an `answer` that explicitly indicates a retrieval failure rather than fabricating content.\n- Implement or extend a logging mechanism (e.g., `trace[\"steps\"]`) to record, for each research step, timestamps, search queries, and selected URLs.\n- Add tests in `tests/test_research_agent_evidence.py` that:\n  - Monkeypatch or mock `SearchEngineTool.search()` and `BrowsingAgent.browse()` to return deterministic responses.\n  - Verify that for a plan with three subquestions, at least three search invocations and some browse invocations are recorded.\n  - Verify that time-budget enforcement works by mocking `time.time()` to simulate time passing.\nRubric:\n- Search-tool usage: when `_gather_evidence()` is called with a plan having N subquestions (N ≥ 2), the mocks MUST observe at least N calls to `SearchEngineTool.search()`, each supplied with a non-empty query string derived from the corresponding subquestion. Tests can assert call counts and inspect the arguments.\n- Browsing-agent integration: for each mock search result, the agent MUST:\n  - Select at least one URL per subquestion and invoke `BrowsingAgent.browse(url, query, language)` using the correct `target_language` from the plan.\n  - Record the returned snippets into the evidence structure such that each evidence item contains at least one non-empty snippet string.\n- Deduplication and coverage: evidence items MUST be deduplicated by URL (e.g., using a set) so that repeated URLs are not stored more than once. A test can simulate duplicate URLs in search responses and assert that the final evidence list has unique URLs.\n- Time-budget compliance: when `max_research_time_s` is artificially set to a small value and `time.time()` is mocked to advance rapidly, `_gather_evidence()` MUST exit early, set `evidence[\"truncated\"]` to `True`, and avoid further search/browse calls after the timeout point.\n- Bilingual behavior: tests that feed a Chinese-language plan (with `\"target_language\": \"zh\"`) MUST show that the queries passed to `SearchEngineTool.search()` or `BrowsingAgent.browse()` preserve the Chinese text and that `evidence` correctly records `\"language\": \"zh\"` for such items.\n- Trace completeness: after calling `run()`, `trace[\"steps\"]` MUST contain an ordered list of step objects each with fields `\"t\"` (timestamp), `\"action\"` in {\"plan\", \"search\", \"browse\"}, and `\"detail\"` (query or URL), enabling later rubric-based auditing.",
  "subtask4": "Query:\nAdd a robust synthesis stage that uses GPT-4.1 to generate final answers grounded in collected evidence, with explicit citation formatting and language control, while preserving the full research trace for evaluation.\nDeliverables:\n- In `research_agent.py`, implement a method (e.g., `_synthesize_answer(self, question: str, plan: dict, evidence: dict) -> dict`) that:\n  - Invokes GPT-4.1 with a dedicated synthesis system prompt (to be defined in `research_agent_prompts.py`) and a message payload that includes: the original question, the structured plan, and a compacted representation of evidence items with stable identifiers (e.g., `\"[S1]\"`, `\"[S2]\"`).\n  - Produces a final answer string in the `plan[\"target_language\"]` (English or Chinese), explicitly instructing the model to quote or paraphrase the evidence and to annotate each factual claim with citations such as `[S1]`, `[S2]` matching the evidence identifiers.\n  - Returns a dict with keys `\"answer\"` (string) and `\"used_sources\"` (list of evidence IDs actually referenced in the answer).\n- In `research_agent_prompts.py`, define a `SYSTEM_PROMPT_RESEARCH_SYNTHESIS` that:\n  - Clearly instructs GPT-4.1 to avoid hallucinating sources or fabricating URLs.\n  - Enforces that all verifiable factual statements must be supported by one or more evidence items, and that unsupported questions should be answered with an explicit statement of uncertainty.\n  - Specifies that the answer language must be `\"en\"` for `target_language = \"en\"` and formal written Chinese for `target_language = \"zh\"`.\n- Modify `run()` so that after evidence gathering, it calls `_synthesize_answer()` and returns the final answer string at `result[\"answer\"]`, while retaining `trace[\"plan\"]` and `trace[\"evidence\"]`.\n- Implement tests in `tests/test_research_agent_synthesis.py` that:\n  - Provide a fixed evidence structure and mock GPT-4.1 outputs to simulate correct and incorrect citation usage.\n  - Validate that `_synthesize_answer()` correctly tracks `\"used_sources\"` and that the final answer respects language and citation constraints.\nRubric:\n- Citation formatting: in the synthesized `answer`, every occurrence of a citation MUST match the regex pattern `\\[S[0-9]+\\]`, and each used citation MUST correspond to an existing evidence item ID passed into `_synthesize_answer()`. A test can parse the answer and cross-check the set of IDs with `\"used_sources\"` and the evidence keys.\n- Evidence grounding: when evidence contains a specific fact (e.g., `\"Einstein published the theory of general relativity in 1915\"` in `S1`), a synthetic LLM output MUST reference `[S1]` alongside that claim. Tests can compare a known mock answer text with expected citations.\n- Language correctness: for a plan with `target_language = \"en\"`, the answer MUST consist predominantly of ASCII letters and standard English punctuation, and MUST NOT contain large segments of Chinese. For `target_language = \"zh\"`, the answer MUST contain Chinese characters and avoid casual mixed-language style except for technical terms.\n- Handling insufficient evidence: if the evidence structure is empty or marked as `\"truncated\": True`, `_synthesize_answer()` MUST either:\n  - Produce an answer that explicitly acknowledges limited evidence (e.g., mentions `\"insufficient evidence\"` or `\"未找到足够的证据\"`) and uses no citations; or\n  - Return a structured error object that `run()` converts into a safe fallback answer. Tests can validate that unsupported questions are not answered confidently.\n- Trace integrity: after `run()`, the returned dict MUST still contain `trace[\"plan\"]` and `trace[\"evidence\"]` unchanged from earlier stages, plus a new field `trace[\"synthesis\"]` summarizing the prompt used for GPT-4.1 (without full text to avoid logging secrets), enabling rubric-based reconstruction of the synthesis step.\n- Bilingual evaluation: tests MUST demonstrate that the same evidence set can yield an English or a Chinese answer solely by altering `plan[\"target_language\"]`, without changing the evidence structure, confirming that the synthesis prompt handles cross-lingual responses correctly.",
  "subtask5": "Query:\nIntegrate the research agent into the end-to-end pipeline for dev/test inference, enforcing all task constraints (time budget, mandatory search, model restrictions, dataset format, and prohibition on searching raw dev/test data), and expose outputs suitable for automatic evaluation.\nDeliverables:\n- Modify `/workspace/repositories/deep_research_agent/main.py` (or the existing entry point) so that:\n  - The script instantiates `ResearchAgent` with GPT-4.1 and GPT-4.1-mini clients, plus the provided `SearchEngineTool` and `BrowsingAgent`, reading configuration from environment variables (`OPENAI_API_KEY`, `OPENAI_BASE_URL` or corresponding Azure variables, and `SERPER_API_KEY`).\n  - For `--split=dev`, it reads `/workspace/datasets/dev.json`, iterates over examples, passes `example[\"prompt\"]` into `ResearchAgent.run()`, and writes predictions to `/workspace/outputs/dev_predictions.json` with fields `\"prompt\"` and `\"answer\"`.\n  - For `--split=test`, it reads `/workspace/datasets/test.json`, runs the agent on each prompt, and writes `/workspace/outputs/test.json` exactly matching the required format.\n- In `research_agent.py`, implement safeguards that:\n  - Enforce `must_use_search`: for each `run()` call on a fact-seeking question, at least one `SearchEngineTool.search()` invocation MUST be made before synthesis; otherwise, the agent returns a safe error answer.\n  - Forbid obvious attempts to search the raw dev/test data by rejecting search queries containing absolute or relative paths like `\"/workspace/datasets/dev.json\"`, `\"/workspace/datasets/test.json\"`, or their URL-encoded/variant forms; such attempts MUST be logged in `trace[\"policy_violations\"]` and result in a safe failure.\n  - Enforce the 10-minute research time limit per question by capping `max_research_time_s` at 600 and aborting long-running searches.\n- Add an integration test script `scripts/test_end_to_end.py` that:\n  - Constructs the agent with mock LLM and search/browse clients.\n  - Runs a small synthetic dataset (3–5 items) through the same path as `main.py` and verifies that the output JSON exists, is valid, and preserves order and prompt text exactly.\n  - Instruments or monkeypatches `SearchEngineTool.search()` to count invocations per question.\nRubric:\n- Output format correctness: after running `python main.py --split=test` in a controlled environment with mocks, the file `/workspace/outputs/test.json` MUST:\n  - Be valid JSON representing a list of objects.\n  - Have the same length as `/workspace/datasets/test.json`.\n  - For each index `i`, satisfy `outputs[i][\"prompt\"] == inputs[i][\"prompt\"]` and contain a non-empty string `outputs[i][\"answer\"]`.\n- Mandatory search usage: instrumentation of `SearchEngineTool.search()` MUST show that for every question processed from dev/test, the search method is called at least once before synthesis. A test can assert that the minimum call count per question is ≥ 1 and log any violations.\n- Model restriction (runtime): the instantiated LLM clients for research and browsing MUST use model identifiers consistent with GPT-4.1 and GPT-4.1-mini only. A test can inspect client configuration objects (e.g., `client.model_name`) and fail if any other model name is used.\n- Dataset path protection: when the research agent is prompted with a question that indirectly encourages searching for `\"/workspace/datasets/dev.json\"` or similar, and the planner produces such a string as a candidate search query, the guard MUST intercept it, add an entry to `trace[\"policy_violations\"]`, skip execution of the search call, and return an answer that explains the query cannot be executed. A test can simulate this behavior by feeding such a prompt and a mocked planner output.\n- Time-limit enforcement: in an integration test where `SearchEngineTool.search()` and `BrowsingAgent.browse()` are artificially slowed (e.g., by sleeping), `ResearchAgent.run()` MUST abort further research operations when the elapsed time exceeds 600 seconds (simulated via time mocking) and produce an answer that mentions timeout or partial research; the trace MUST mark `evidence[\"truncated\"] = True`.\n- Compatibility with evaluation script: running `python /workspace/scripts/eval_on_dev.py` after generating dev predictions MUST complete without format errors, demonstrating that the agent’s dev output is structurally compatible with the provided evaluation pipeline."
}