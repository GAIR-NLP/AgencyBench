{
  "subtask_count": 5,
  "subtask1": "Query:\nDesign a baseline reaction-rate equation inside `equation.py` so that the derivative dA/dt reflects a first-order dependence on time t and concentration A. Work from the project root using `equation.py` for the model, `analysis.py` plus `equation.parquet` to inspect the (output, t, A) tuples, and `evaluate_equation.py` to fit parameters and print the mean squared error (MSE). Do not alter other assets; observe the data via the helper scripts. Final goal: after re-optimizing parameters, `python3 evaluate_equation.py` must report loss < 1e-1, and the console log should clearly show the achieved value. Expected output: the updated analytical expression and the evaluation stdout proving the target was met.\nDeliverables:\n- `equation.py` containing a differentiable first-order kinetics expression returning a NumPy array while keeping the original signature and imports.\n- `logs/subtask1_evaluate.txt` (or equivalent captured stdout) produced by `python3 evaluate_equation.py` in the project root showing the achieved loss.\n- `docs/subtask1_rationale.md` summarizing (in English) the chosen structure, parameter roles, and how it connects to the dataset.\nRubric:\n- Training loss is authoritative: let loss be the final `MSE` reported by `evaluate_equation.py`. Score = 0 if loss >= 5e-2, Score = 10 if loss <= 1e-3, otherwise Score = 10 * (5e-2 - loss) / (5e-2 - 1e-3). Missing documentation or failure to modify `equation.py` deducts 5 points from the computed score (floored at 0).",
  "subtask2": "Query:\nExtend the baseline model so it encodes explicit nonlinear interactions (e.g., saturation A/(1 + kA), exponential decay exp(-k*t), or mixed power terms t*A**2) capturing curvature observed in the measurements. Continue using the helper scripts; every edit still occurs in `equation.py`, and diagnostics rely on `python3 analysis.py` plus `python3 evaluate_equation.py`. Goal: demonstrate a nonlinear coupling and reach MSE < 5e-2 after optimization. Provide the console output and describe the new nonlinear behavior.\nDeliverables:\n- `equation.py` updated with identifiable nonlinear t–A interaction terms and brief inline comments (English) explaining any new auxiliary computations.\n- `logs/subtask2_evaluate.txt` capturing the complete evaluation stdout with loss < 5e-2.\n- `docs/subtask2_rationale.md` outlining why the introduced nonlinearities fit the chemistry interpretation and how they changed the optimizer behavior.\nRubric:\n- Primary score uses the evaluation loss: let loss be the optimized MSE. Score = 0 if loss >= 2e-3, Score = 10 if loss <= 5e-4, else Score = 10 * (2e-3 - loss) / (2e-3 - 5e-4). Submissions lacking a clearly nonlinear term default to Score = 0 even if the numeric loss threshold is satisfied; missing the requested rationale deducts 5 points from the computed score (floored at 0).",
  "subtask3": "Query:\nCapture coupled time–concentration dynamics by blending multiplicative or rational expressions (e.g., t*A/(1 + k t), logistic dampers, or two-timescale exponentials) so both early spikes and late-time plateaus are modeled smoothly. Operate under the same constraints, only editing `equation.py` and verifying with `evaluate_equation.py`. Target an optimized MSE < 1e-2 and ensure the functional form remains differentiable for the optimizer.\nDeliverables:\n- `equation.py` incorporating at least one coupled term f(t, A) that mixes the variables (such as t*A/(1 + p0*t) or exp(-p1*t)*A**2) plus short English comments clarifying stiff vs. slow pathways.\n- `logs/subtask3_evaluate.txt` showing the evaluation command, optimizer convergence trace, and a final loss < 1e-2.\n- `docs/subtask3_rationale.md` describing the coupled dynamics, parameter interpretation, and any stability steps taken.\nRubric:\n- Let loss denote the reported MSE. Score = 0 if loss >= 6e-4, Score = 10 if loss <= 1e-5, otherwise Score = 10 * (6e-4 - loss) / (6e-4 - 1e-5). Implementations missing mixed t–A terms automatically receive Score = 0; missing the rationale document deducts 5 points from the computed score (floored at 0).",
  "subtask4": "Query:\nStabilize the discovered equation against stiff behavior by incorporating damping or saturation motifs (e.g., Michaelis–Menten denominators, logistic clipping, blended fast/slow exponentials) so the optimizer remains well-behaved for extreme concentrations. Maintain the prior workflow: inspect via `analysis.py`, modify `equation.py`, and validate with `evaluate_equation.py`. Required target is MSE < 5e-3, and the resulting structure must stay numerically stable (no divide-by-zero or overflow for typical dataset ranges).\nDeliverables:\n- `equation.py` featuring explicit stabilizing terms (denominators bounded away from zero, smooth activation functions, etc.) plus concise English comments referencing how each term mitigates stiffness.\n- `logs/subtask4_evaluate.txt` recording the evaluation run with loss < 5e-3 and a note about any regularization parameters.\n- `docs/subtask4_rationale.md` detailing stability considerations, damping parameter roles, and verification steps (e.g., additional quick sweeps).\nRubric:\n- With loss as the optimized MSE, Score = 0 if loss >= 2e-5, Score = 10 if loss <= 5e-6, else Score = 10 * (2e-5 - loss) / (2e-5 - 5e-6). Submissions exhibiting numerical instability (NaNs during evaluation) default to Score = 0; missing the requested documentation deducts 5 points from the computed score (floored at 0).",
  "subtask5": "Query:\nFinalize a high-fidelity, interpretable equation by layering higher-order or competing-pathway terms (e.g., dual exponentials, delayed response kernels approximated with rational filters, or inhibitory branches) that keep parameters physically meaningful while pushing the fit under 1e-3. Continue using the provided scripts only; run `python3 evaluate_equation.py` to verify the optimized loss and ensure total runtime stays under two minutes. Document how each term contributes to fidelity and how the optimizer settings were adjusted, if at all.\nDeliverables:\n- `equation.py` containing the production-ready closed-form expression (with English comments noting each pathway) and no extraneous debugging prints.\n- `logs/subtask5_evaluate.txt` capturing the final evaluation output that reports MSE < 1e-3.\n- `docs/subtask5_rationale.md` summarizing higher-order effects, parameter interpretability, and any diagnostic plots or metrics referenced.\nRubric:\n- Let loss be the final MSE from `evaluate_equation.py`. Score = 0 if loss >= 6e-6, Score = 10 if loss <= 1e-7, else Score = 10 * (6e-6 - loss) / (6e-6 - 1e-7). Missing documentation, unverifiable runtime (no log), or failure to keep parameters interpretable (e.g., undefined behavior for dataset ranges) yields Score = 0 despite the numeric loss."
}
