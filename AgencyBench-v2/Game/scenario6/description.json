{
  "subtask_count": 5,
  "subtask1": "Query:\nCreate a static Lianliankan (tile-matching) launch view that renders a centered 10×8 board with labelled axes (A–J across the top and 1–8 down the left). Include a heads-up area `#hud` that shows a stub timer and remaining pairs, a `#tile-grid` container, a legend `#legend` explaining tile colors, and a prominent `#start-btn` labelled `Start Puzzle`. Automatically call `window.app.initializeGrid()` on load so the 80 placeholder tiles render without any manual interaction.\nDeliverables:\n- `index.html` linking `styles.css` and `app.js` via relative paths and containing `#hud`, `#tile-grid`, `#legend`, and `#start-btn`.\n- `styles.css` defining a 640px×512px grid (10 columns by 8 rows), centering the puzzle stack, and spacing the legend beneath the board with matching typography.\n- `app.js` exposing `window.app` with methods `initializeGrid()` and `describeLayout()`; `describeLayout()` returns an object with keys `startButton`, `legend`, `hud`, and `tiles`, where `tiles` maps coordinates like `\"E3\"` to `{ \"x\": number, \"y\": number }` viewport positions.\nRubric:\n- Visual grid: automation captures `puzzle_layout.png` and confirms `#tile-grid` is exactly 640±4px wide and 512±4px tall, centered within ±6px both horizontally and vertically, and packed with 80 `.tile` placeholders showing faint glyphs.\n- Controls placement: `describeLayout()` must report `startButton` roughly at `{ \"x\": 120±6, \"y\": 110±6 }`. The legend top edge must sit within 70±6px of the grid bottom, and `#hud` must hug the board with a top offset of 48±6px.\n- DOM contract: every `.tile` element must carry `data-cell=\"<letter><number>\"` and `data-value` attributes plus inline text for screen readers. Missing IDs or fewer than 80 tiles result in failure.\n- API bootstrapping: invoking `window.app.initializeGrid()` twice must be idempotent, leaving exactly one grid instance, populated `describeLayout().tiles`, and a non-empty HUD summary.",
  "subtask2": "Query:\nEnable interactive tile selection so reviewers can click two matching icons to clear them if a valid straight or L-shaped path exists. Highlight the current selection, pulse matched tiles for 400ms, update a `#status-bar` element, and surface controls `#hint-button`, `#shuffle-button`, and `#combo-indicator` inside the HUD. Keep all assets from subtask1.\nDeliverables:\n- Continue shipping `index.html`, `styles.css`, and `app.js`, adding the HUD controls plus a text node `#status-message` beneath the grid.\n- Extend `window.app` with `debugState()` (returns `{ selections: string[], matchedPairs: string[], shuffleCount: number }`), `setDemoPairs(sequence)` where `sequence` is an array of `{ \"id\": string, \"coords\": [c1, c2], \"value\": string }`, `triggerHint()`, and `applyShuffle()`. Automation will seed tiles via `setDemoPairs` before interacting.\nRubric:\n- Matching flow: after calling `setDemoPairs([{ \"id\": \"tutorial\", \"coords\": [\"C3\", \"E3\"], \"value\": \"lantern\" }, { \"id\": \"blocked\", \"coords\": [\"D5\", \"D6\"], \"value\": \"fan\" }])`, automation clicks `C3` then `E3` using the coordinates from `describeLayout().tiles`. `debugState().matchedPairs` must include `\"tutorial\"`, both tiles gain class `.cleared`, and `#combo-indicator` reads `Combo x1`.\n- Invalid selection: selecting `D5` twice must leave `matchedPairs` unchanged, reset the highlight, and set `#status-message` text to `Select a different tile`.\n- Shuffle control: clicking `#shuffle-button` calls `applyShuffle()`, increments `debugState().shuffleCount`, and pushes `Tiles shuffled` into the status bar within 500ms.\n- Regression: layout metrics, tile count, and initializeGrid() behavior from subtask1 remain within tolerance.",
  "subtask3": "Query:\nIntroduce a timed challenge layer with live countdown, life tracking, undo/redo, and a replay feature. Display `#timer`, `#lives-remaining`, and a toolbar `#controls` containing buttons `button[data-action=\"undo\"]`, `button[data-action=\"redo\"]`, and `button[data-action=\"replay\"]` under the status bar. Persist turn history inside `session.log` with CSV rows `timestamp,event,detail`.\nDeliverables:\n- Maintain the existing three primary files and append `session.log`. Keep HUD controls from subtask2 and add a banner `#winner-banner` for completion text.\n- Extend `window.app` with `undoMatch()`, `redoMatch()`, `startReplay()`, `checkCleared()` (returns `{ cleared: boolean, remaining: number }`), `registerStrike()`, and `exportLog()` that mirrors `session.log`.\nRubric:\n- Win scenario: automation plays the seeded sequence `C3,E3`, `B4,B6`, `H2,H4`. After the third match `checkCleared()` must report `{ cleared: true, remaining: 0 }`, `#winner-banner` displays `Board cleared!`, and manual clicks are ignored until the puzzle is re-seeded via `initializeGrid()` or a later reset action.\n- Undo/redo: clicking undo then redo must remove and restore the last pair while updating `debugState().matchedPairs` length accordingly and logging `undo`/`redo` entries.\n- Replay controls: invoking `startReplay()` via the toolbar must animate tiles in chronological order with ≥300ms spacing and record a `replay_start` + `replay_end` pair inside `session.log`. Manual clicks stay disabled during playback.\n- Timer + lives: `#timer` counts down from at least 90 seconds with mm:ss text, `#lives-remaining` decrements when automation triggers `window.app.registerStrike()`, and both values surface in `debugState()`. Existing layout tolerances continue to hold.",
  "subtask4": "Query:\nAdd a persistence drawer so reviewers can save, load, and reset puzzles without losing their logs or combo history. Place a panel `#persistence` beneath the controls containing buttons `#save-puzzle`, `#load-puzzle`, `#reset-puzzle`, the read-only `<textarea id=\"state-json\">`, and a scoreboard `#scoreboard` with counters `.perfect-clears`, `.hints-used`, `.shuffles`. Saving writes the serialized state to the textarea and `localStorage['lianliankan-state']`. Loading parses the textarea, restores cleared tiles, HUD text, timer, combos, and session log. Reset only wipes the current puzzle but keeps scoreboard totals.\nDeliverables:\n- Continue shipping the three core files plus `session.log`. Persisted saves must rehydrate automatically on reload via `localStorage`.\n- Extend `window.app` with `serializeState()`, `applyState(serialized)`, `resetPuzzle()`, and `getScoreboard()` returning `{ perfectClears: number, hints: number, shuffles: number }`.\nRubric:\n- Save flow: after several matches, clicking `#save-puzzle` updates `#state-json` with JSON containing `moves`, `timer`, and `scoreboard`. `serializeState()` must return identical data, and `localStorage['lianliankan-state']` holds the same string.\n- Restore flow: invoking `resetPuzzle()` empties the grid but keeps scoreboard counts. Calling `applyState()` with the saved JSON rebuilds cleared tiles, combo text, timer, and `debugState().matchedPairs`.\n- Scoreboard: when automation completes a puzzle then resets, `getScoreboard().perfectClears` increments while the other counters stay unchanged unless hints or shuffles were used. Visual labels in `#scoreboard` must match the returned numbers.\n- Regression: undo/redo/replay, logging, tiles, and HUD placement behave as defined in subtasks 1–3.",
  "subtask5": "Query:\nLayer a diagnostics lab and scripted scenarios to stress-test persistence. Add a toggle button `#toggle-lab` that reveals a right-aligned `<aside id=\"lab-inspector\">` containing current depth, total matches, elapsed milliseconds, node count, and a table with headers `Metric` and `Value`. Load scenario data from `hard_cases.json` with at least two entries containing `id`, `label`, `layout`, `steps`, and `winner`. Provide playback controls inside the lab to preview scenarios, capture screenshots, and measure performance.\nDeliverables:\n- Keep the previous assets and ship `hard_cases.json`. The lab must list aggregated stats for the active puzzle and the selected scenario (e.g., path length, remaining shuffles) plus a button group to `Preview`, `Play`, and `Export`.\n- Extend `window.app` with `loadScenario(id)`, `playScenario(id, options)`, `getDiagnostics()`, `summarizeScenario(id)`, and `estimateHeap()`. `playScenario` returns a Promise that resolves once the animation completes while blocking manual clicks.\nRubric:\n- Scenario import: calling `loadScenario(0)` must place tiles per the fixture, update `#winner-banner` with the scenario winner, and add lines to `session.log`. `summarizeScenario(0)` returns an object with keys `totalTiles`, `pairs`, and `longestPath`.\n- Playback: invoking `playScenario(1, { intervalMs: 240 })` replays the scenario in chronological order with ≥200ms spacing, reuses undo/redo guards, and re-enables manual clicks afterward. Video `scenario_replay.webm` must show the tiles animating.\n- Diagnostics: `getDiagnostics()` returns `{ depth, elapsedMs, nodes, topRoutes }`. While the lab is visible, the table stays 260±6px wide at 60±6px from the right edge and appears in `diagnostics.png`.\n- Stability: calling `estimateHeap()` five times yields non-decreasing integers ≤64000000. All expectations from subtasks 1–4 continue to hold."
}